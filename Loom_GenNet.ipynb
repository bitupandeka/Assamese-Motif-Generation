{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4wqkQ6KiXtbs"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
        "\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import keras\n",
        "from keras import layers\n",
        "from keras import ops"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "gg84TftqYbF5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path = \"/content/drive/MyDrive/dataset_folder\""
      ],
      "metadata": {
        "id": "r2NsxDLHYhj3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to load and preprocess an image\n",
        "def load_image(image_path):\n",
        "    image = tf.io.read_file(image_path)\n",
        "    image = tf.image.decode_jpeg(image, channels=3)  # Change to png if necessary\n",
        "    image = tf.image.resize(image, [image_size, image_size], antialias=True)\n",
        "    image = tf.clip_by_value(image / 255.0, 0.0, 1.0)\n",
        "    return image"
      ],
      "metadata": {
        "id": "cu1EtQIBYq0H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data\n",
        "dataset_name = \"LoomGen\"\n",
        "dataset_repetitions = 5\n",
        "num_epochs = 200\n",
        "image_size = 64\n",
        "\n",
        "kid_image_size = 75\n",
        "\n",
        "kid_diffusion_steps = 10  # For KID computation\n",
        "plot_diffusion_steps = 60  # For visualization\n",
        "\n",
        "# sampling\n",
        "min_signal_rate = 0.02\n",
        "max_signal_rate = 0.95\n",
        "\n",
        "# architecture\n",
        "embedding_dims = 32\n",
        "embedding_max_frequency = 1000.0\n",
        "widths = [32, 64, 96, 128]\n",
        "block_depth = 3\n",
        "\n",
        "# optimization\n",
        "batch_size = 16\n",
        "ema = 0.999\n",
        "learning_rate = 1e-3\n",
        "weight_decay = 1e-4"
      ],
      "metadata": {
        "id": "Z8N_UF8gYvsm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_full_dataset(directory):\n",
        "    image_paths = [os.path.join(directory, fname)\n",
        "                  for fname in os.listdir(directory)\n",
        "                  if fname.endswith(('.jpg', '.png'))]\n",
        "\n",
        "    full_dataset = tf.data.Dataset.from_tensor_slices(image_paths)\n",
        "    full_dataset = full_dataset.map(load_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    full_dataset = full_dataset.cache()\n",
        "    full_dataset = full_dataset.repeat(dataset_repetitions)\n",
        "    full_dataset = full_dataset.shuffle(10 * batch_size)\n",
        "    full_dataset = full_dataset.batch(batch_size, drop_remainder=True)\n",
        "    full_dataset = full_dataset.prefetch(tf.data.AUTOTUNE)\n",
        "    return full_dataset\n",
        "\n",
        "full_dataset = prepare_full_dataset(dataset_path)"
      ],
      "metadata": {
        "id": "pVN__P3TZvQv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#===========================#\n",
        "# Loom-GenNet Architecture  #\n",
        "#===========================#\n",
        "\n",
        "@keras.saving.register_keras_serializable()\n",
        "def sinusoidal_embedding(x):\n",
        "    embedding_min_frequency = 1.0\n",
        "    frequencies = ops.exp(\n",
        "        ops.linspace(\n",
        "            ops.log(embedding_min_frequency),\n",
        "            ops.log(embedding_max_frequency),\n",
        "            embedding_dims // 2,\n",
        "        )\n",
        "    )\n",
        "    angular_speeds = ops.cast(2.0 * math.pi * frequencies, \"float32\")\n",
        "    embeddings = ops.concatenate(\n",
        "        [ops.sin(angular_speeds * x), ops.cos(angular_speeds * x)], axis=3\n",
        "    )\n",
        "    return embeddings\n",
        "\n",
        "def ResidualBlock(width):\n",
        "    def apply(x):\n",
        "        input_width = x.shape[3]\n",
        "        if input_width == width:\n",
        "            residual = x\n",
        "        else:\n",
        "            residual = layers.Conv2D(width, kernel_size=1)(x)\n",
        "        x = layers.BatchNormalization(center=True, scale=True)(x)\n",
        "        x = layers.Conv2D(width, kernel_size=3, padding=\"same\", activation=\"relu\")(x)\n",
        "        x = layers.Conv2D(width, kernel_size=3, padding=\"same\")(x)\n",
        "        x = layers.Add()([x, residual])\n",
        "        return x\n",
        "    return apply\n",
        "\n",
        "def SpatialPyramidPooling(x, levels=[1, 2, 4]):\n",
        "    \"\"\"Apply SPP to extract multi-scale features.\"\"\"\n",
        "    pooled_features = []\n",
        "    for level in levels:\n",
        "        pool_size = (max(1, x.shape[1] // level), max(1, x.shape[2] // level))\n",
        "        pooled = layers.AveragePooling2D(pool_size=pool_size, strides=pool_size)(x)\n",
        "        # Adjust channels with 1x1 convolution and upsample to original size\n",
        "        pooled = layers.Conv2D(x.shape[3], 1, padding='same')(pooled)\n",
        "        pooled = layers.UpSampling2D(size=(x.shape[1] // pooled.shape[1], x.shape[2] // pooled.shape[2]), interpolation='bilinear')(pooled)\n",
        "        pooled_features.append(pooled)\n",
        "    return layers.Concatenate()(pooled_features)\n",
        "\n",
        "def get_network(image_size, widths, block_depth):\n",
        "    input_image = keras.Input(shape=(image_size, image_size, 3))\n",
        "    noise_variances = keras.Input(shape=(1, 1, 1))\n",
        "\n",
        "    e = layers.Lambda(sinusoidal_embedding)(noise_variances)\n",
        "    e = layers.UpSampling2D(size=image_size, interpolation=\"nearest\")(e)\n",
        "\n",
        "    # ===================================#\n",
        "    # Asymmetric Dual Encoder Structure  #\n",
        "    # ===================================#\n",
        "\n",
        "    # Encoder Path 1 (3x3 convs with dilated convolutions)\n",
        "    x_left = layers.Conv2D(widths[0], 3, padding='same')(input_image)\n",
        "    x_left = layers.Concatenate()([x_left, e])\n",
        "    x_left = layers.Conv2D(widths[0], 3, padding='same', dilation_rate=2)(x_left)\n",
        "\n",
        "    # Encoder Path 2 (5x5 convs with dilated convolutions)\n",
        "    x_bottom = layers.Conv2D(widths[0], 5, padding='same')(input_image)\n",
        "    x_bottom = layers.Concatenate()([x_bottom, e])\n",
        "    x_bottom = layers.Conv2D(widths[0], 5, padding='same', dilation_rate=2)(x_bottom)\n",
        "\n",
        "    skips = []\n",
        "\n",
        "    # Process both encoders\n",
        "    for width in widths[:-1]:\n",
        "        # Encoder 1 (3x3 with increasing dilation)\n",
        "        x_left = ResidualBlock(width)(x_left)\n",
        "        skips.append(x_left)\n",
        "        x_left = layers.AveragePooling2D(2)(x_left)\n",
        "        x_left = layers.Conv2D(width, 3, padding='same', dilation_rate=3)(x_left)  # Increased dilation\n",
        "\n",
        "        # Encoder 2 (5x5 with increasing dilation)\n",
        "        x_bottom = ResidualBlock(width)(x_bottom)\n",
        "        skips.append(x_bottom)\n",
        "        x_bottom = layers.AveragePooling2D(2)(x_bottom)\n",
        "        x_bottom = layers.Conv2D(width, 5, padding='same', dilation_rate=3)(x_bottom)  # Increased dilation\n",
        "\n",
        "    # ======================================#\n",
        "    # Spatial Pyramid Pooling at Bottleneck #\n",
        "    # ======================================#\n",
        "    x_left_spp = SpatialPyramidPooling(x_left, levels=[1, 2, 4])\n",
        "    x_bottom_spp = SpatialPyramidPooling(x_bottom, levels=[1, 2, 4])\n",
        "    x = layers.Concatenate()([x_left_spp, x_bottom_spp])\n",
        "    x = layers.Conv2D(widths[-1], 1, padding='same')(x)  # Reduce channels to match bottleneck width\n",
        "\n",
        "    for _ in range(block_depth):\n",
        "        x = ResidualBlock(widths[-1])(x)\n",
        "\n",
        "    # ===============#\n",
        "    # Single Decoder #\n",
        "    # ===============#\n",
        "    for width in reversed(widths[:-1]):\n",
        "        x = layers.UpSampling2D(2, interpolation='bilinear')(x)\n",
        "\n",
        "        skip = layers.Concatenate()([skips.pop(), skips.pop()])\n",
        "        x = layers.Concatenate()([x, skip])\n",
        "        x = ResidualBlock(width)(x)\n",
        "\n",
        "    # Output noise prediction\n",
        "    output = layers.Conv2D(3, 1, kernel_initializer='zeros')(x)\n",
        "\n",
        "    return keras.Model([input_image, noise_variances], output, name=\"Loom-GenNet\")"
      ],
      "metadata": {
        "id": "tU27HIGDZ10u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@keras.saving.register_keras_serializable()\n",
        "class DiffusionModel(keras.Model):\n",
        "    def __init__(self, image_size, widths, block_depth):\n",
        "        super().__init__()\n",
        "\n",
        "        self.normalizer = layers.Normalization()\n",
        "        self.network = get_network(image_size, widths, block_depth)\n",
        "        self.ema_network = keras.models.clone_model(self.network)\n",
        "\n",
        "    def compile(self, **kwargs):\n",
        "        super().compile(**kwargs)\n",
        "\n",
        "        self.noise_loss_tracker = keras.metrics.Mean(name=\"n_loss\")\n",
        "        self.image_loss_tracker = keras.metrics.Mean(name=\"i_loss\")\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [self.noise_loss_tracker, self.image_loss_tracker]\n",
        "\n",
        "    def denormalize(self, images):\n",
        "        images = self.normalizer.mean + images * self.normalizer.variance**0.5\n",
        "        return ops.clip(images, 0.0, 1.0)\n",
        "\n",
        "    def diffusion_schedule(self, diffusion_times):\n",
        "        start_angle = ops.cast(ops.arccos(max_signal_rate), \"float32\")\n",
        "        end_angle = ops.cast(ops.arccos(min_signal_rate), \"float32\")\n",
        "\n",
        "        diffusion_angles = start_angle + diffusion_times * (end_angle - start_angle)\n",
        "\n",
        "        signal_rates = ops.cos(diffusion_angles)\n",
        "        noise_rates = ops.sin(diffusion_angles)\n",
        "\n",
        "        return noise_rates, signal_rates\n",
        "\n",
        "    def denoise(self, noisy_images, noise_rates, signal_rates, training):\n",
        "        if training:\n",
        "            network = self.network\n",
        "        else:\n",
        "            network = self.ema_network\n",
        "\n",
        "        pred_noises = network([noisy_images, noise_rates**2], training=training)\n",
        "        pred_images = (noisy_images - noise_rates * pred_noises) / signal_rates\n",
        "\n",
        "        return pred_noises, pred_images\n",
        "\n",
        "    def reverse_diffusion(self, initial_noise, diffusion_steps):\n",
        "        num_images = initial_noise.shape[0]\n",
        "        step_size = 1.0 / diffusion_steps\n",
        "\n",
        "        next_noisy_images = initial_noise\n",
        "        for step in range(diffusion_steps):\n",
        "            noisy_images = next_noisy_images\n",
        "\n",
        "            diffusion_times = ops.ones((num_images, 1, 1, 1)) - step * step_size\n",
        "            noise_rates, signal_rates = self.diffusion_schedule(diffusion_times)\n",
        "            pred_noises, pred_images = self.denoise(\n",
        "                noisy_images, noise_rates, signal_rates, training=False\n",
        "            )\n",
        "\n",
        "            next_diffusion_times = diffusion_times - step_size\n",
        "            next_noise_rates, next_signal_rates = self.diffusion_schedule(\n",
        "                next_diffusion_times\n",
        "            )\n",
        "            next_noisy_images = (\n",
        "                next_signal_rates * pred_images + next_noise_rates * pred_noises\n",
        "            )\n",
        "\n",
        "        return pred_images\n",
        "\n",
        "    def generate(self, num_images, diffusion_steps):\n",
        "        # noise -> images -> denormalized images\n",
        "        initial_noise = keras.random.normal(\n",
        "            shape=(num_images, image_size, image_size, 3)\n",
        "        )\n",
        "        generated_images = self.reverse_diffusion(initial_noise, diffusion_steps)\n",
        "        generated_images = self.denormalize(generated_images)\n",
        "        return generated_images\n",
        "\n",
        "    def train_step(self, images):\n",
        "        # normalize images to have standard deviation of 1, like the noises\n",
        "        images = self.normalizer(images, training=True)\n",
        "        batch_size = tf.shape(images)[0]\n",
        "        noises = keras.random.normal(shape=(batch_size, image_size, image_size, 3))\n",
        "\n",
        "        # sample uniform random diffusion times\n",
        "        diffusion_times = keras.random.uniform(\n",
        "            shape=(batch_size, 1, 1, 1), minval=0.0, maxval=1.0\n",
        "        )\n",
        "        noise_rates, signal_rates = self.diffusion_schedule(diffusion_times)\n",
        "        # mix the images with noises accordingly\n",
        "        noisy_images = signal_rates * images + noise_rates * noises\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            # train the network to separate noisy images to their components\n",
        "            pred_noises, pred_images = self.denoise(\n",
        "                noisy_images, noise_rates, signal_rates, training=True\n",
        "            )\n",
        "\n",
        "            noise_loss = self.loss(noises, pred_noises)  # used for training\n",
        "            image_loss = self.loss(images, pred_images)  # only used as metric\n",
        "\n",
        "        gradients = tape.gradient(noise_loss, self.network.trainable_weights)\n",
        "        self.optimizer.apply_gradients(zip(gradients, self.network.trainable_weights))\n",
        "\n",
        "        self.noise_loss_tracker.update_state(noise_loss)\n",
        "        self.image_loss_tracker.update_state(image_loss)\n",
        "\n",
        "        # track the exponential moving averages of weights\n",
        "        for weight, ema_weight in zip(self.network.weights, self.ema_network.weights):\n",
        "            ema_weight.assign(ema * ema_weight + (1 - ema) * weight)\n",
        "\n",
        "        return {m.name: m.result() for m in self.metrics[:-1]}\n",
        "\n",
        "    def test_step(self, images):\n",
        "        # normalize images to have standard deviation of 1, like the noises\n",
        "        images = self.normalizer(images, training=False)\n",
        "        batch_size = tf.shape(images)[0]\n",
        "        noises = keras.random.normal(shape=(batch_size, image_size, image_size, 3))\n",
        "\n",
        "        # sample uniform random diffusion times\n",
        "        diffusion_times = keras.random.uniform(\n",
        "            shape=(batch_size, 1, 1, 1), minval=0.0, maxval=1.0\n",
        "        )\n",
        "        noise_rates, signal_rates = self.diffusion_schedule(diffusion_times)\n",
        "        # mix the images with noises accordingly\n",
        "        noisy_images = signal_rates * images + noise_rates * noises\n",
        "\n",
        "        # use the network to separate noisy images to their components\n",
        "        pred_noises, pred_images = self.denoise(\n",
        "            noisy_images, noise_rates, signal_rates, training=False\n",
        "        )\n",
        "\n",
        "        noise_loss = self.loss(noises, pred_noises)\n",
        "        image_loss = self.loss(images, pred_images)\n",
        "\n",
        "        self.image_loss_tracker.update_state(image_loss)\n",
        "        self.noise_loss_tracker.update_state(noise_loss)\n",
        "\n",
        "        return {m.name: m.result() for m in self.metrics}\n",
        "\n",
        "    def plot_images(self, epoch=None, logs=None, num_rows=3, num_cols=6):\n",
        "        # plot random generated images for visual evaluation of generation quality\n",
        "        generated_images = self.generate(\n",
        "            num_images=num_rows * num_cols,\n",
        "            diffusion_steps=plot_diffusion_steps,\n",
        "        )\n",
        "\n",
        "        plt.figure(figsize=(num_cols * 2.0, num_rows * 2.0))\n",
        "        for row in range(num_rows):\n",
        "            for col in range(num_cols):\n",
        "                index = row * num_cols + col\n",
        "                plt.subplot(num_rows, num_cols, index + 1)\n",
        "                plt.imshow(generated_images[index])\n",
        "                plt.axis(\"off\")\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        plt.close()"
      ],
      "metadata": {
        "id": "pFjIJEvlbtFI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create and compile the model\n",
        "model = DiffusionModel(image_size, widths, block_depth)\n",
        "\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.AdamW(\n",
        "        learning_rate=learning_rate, weight_decay=weight_decay\n",
        "    ),\n",
        "    loss=keras.losses.mean_squared_error,\n",
        ")\n",
        "model.normalizer.adapt(full_dataset)\n",
        "\n",
        "history = model.fit(\n",
        "    full_dataset,\n",
        "    epochs=num_epochs,\n",
        "    callbacks=[\n",
        "        # plot generated images at the end of each epoch\n",
        "        keras.callbacks.LambdaCallback(on_epoch_end=model.plot_images),\n",
        "    ],\n",
        ")"
      ],
      "metadata": {
        "id": "bR83GGwacftf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}